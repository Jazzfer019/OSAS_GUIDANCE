# 1Ô∏è‚É£ Import packages
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import LinearSVC
from sklearn.calibration import CalibratedClassifierCV
from sklearn.metrics import accuracy_score, confusion_matrix
import joblib
import string
import numpy as np

# 2Ô∏è‚É£ Load dataset
df = pd.read_excel(r"C:\Users\Harold Arevalo\Downloads\cvsu_violation_updated_dataset.xlsx")

# Handle missing values and ensure 'violation' is in string format
df = df.dropna(subset=['violation'])  # Drop rows where 'violation' is NaN
df['violation'] = df['violation'].astype(str)  # Ensure 'violation' is string type

# Extract texts and labels
texts = df['text']
labels = df['violation']

# 3Ô∏è‚É£ Check dataset
print("Dataset preview:")
print(df.head())
print(f"Total rows: {df.shape[0]}\n")

# 4Ô∏è‚É£ Preprocessing function
def preprocess(text):
    """Lowercase and remove punctuation, handle non-string values"""
    if isinstance(text, str):  # Ensure the text is a string
        return text.lower().translate(str.maketrans('', '', string.punctuation))
    else:
        return ''  # Return empty string for non-string values

# Apply preprocessing
texts = texts.apply(preprocess)

# 5Ô∏è‚É£ Train/test split
X_train, X_test, y_train, y_test = train_test_split(
    texts, labels, test_size=0.2, random_state=42
)

# 6Ô∏è‚É£ TF-IDF Vectorizer
vectorizer = TfidfVectorizer()
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)

# 7Ô∏è‚É£ Train Linear SVM (with probabilities)
base_model = LinearSVC()
model = CalibratedClassifierCV(base_model)  # Enable predict_proba for probability outputs
model.fit(X_train_tfidf, y_train)

# 8Ô∏è‚É£ Evaluation
y_pred = model.predict(X_test_tfidf)
accuracy = accuracy_score(y_test, y_pred)
print(f"Test Accuracy: {accuracy:.2f}")

cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(cm)

# 9Ô∏è‚É£ Save model + vectorizer
joblib.dump(model, "model.pkl")
joblib.dump(vectorizer, "vectorizer.pkl")
print("‚úÖ Model and vectorizer saved successfully!")

# üîü Save violation ‚Üí section mapping
violation_to_section = dict(zip(df['violation'], df['section']))
joblib.dump(violation_to_section, "violation_to_section.pkl")
print("‚úÖ Violation ‚Üí Section mapping saved successfully!")

# 1Ô∏è‚É£1Ô∏è‚É£ Save violation ‚Üí standard text
# Get FIRST example text for each violation
violation_to_standard_text = df.groupby("violation")["text"].first().to_dict()

joblib.dump(violation_to_standard_text, "violation_to_standard_text.pkl")
print("‚úÖ Violation ‚Üí Standard Text mapping saved successfully!")

# 1Ô∏è‚É£2Ô∏è‚É£ Prediction Function
def predict_violation(sentence, top_n=3):
    sentence_proc = preprocess(sentence)  # Preprocess the input sentence
    vectorized = vectorizer.transform([sentence_proc])  # Vectorize the input sentence
    pred = model.predict(vectorized)[0]  # Predict the violation label

    # Predictive text (top N)
    if hasattr(model, "predict_proba"):
        probs = model.predict_proba(vectorized)[0]  # Get probability scores
        classes = model.classes_
        top_indices = np.argsort(probs)[::-1][:top_n]  # Get top N predictions
        predictive_text = ", ".join([f"{classes[i]} ({probs[i]*100:.1f}%)" for i in top_indices])
    else:
        predictive_text = pred

    # Get the predicted section and standard text
    predicted_section = violation_to_section.get(pred, "Unknown")
    standard_text = violation_to_standard_text.get(pred, "No sample text available")

    return {
        "input_text": sentence,
        "predicted_violation": pred,
        "predicted_section": predicted_section,
        "predictive_text": predictive_text,
        "standard_text": standard_text
    }

# üîÅ Test predictive function
test_sentences = [
    "Binato ang bintana sa classroom",
    "Student copied answers from classmate",
    "Uminom sa loob ng classroom"
]

for s in test_sentences:
    print(predict_violation(s))
